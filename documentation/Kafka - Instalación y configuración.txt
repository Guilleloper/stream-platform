#######################################
# KAFKA - INSTALACIÓN Y CONFIGURACIÓN #
#######################################


1. INSTALACIÓN
2. CONFIGURACIÓN
3. COSAS PENDIENTES

-----------------------------------------------------------------------------------------------------------------------------

1. INSTALACIÓN

Los pasos indicados a continuación deben realizarse en todos y cada uno de los nodos que vayan a conformar el cluster de Kafka:

- Subir el software a /var/tmp:
  # md5sum /var/tmp/jdk-8u131-linux-x64.rpm
  9024d13ec651d07de450d465f14065a6  /var/tmp/jdk-8u131-linux-x64.rpm
  # md5sum /var/tmp/kafka_2.11-0.11.0.2.tgz
  40474611457eabcee610dac4fca22e7b  /var/tmp/kafka_2.11-0.11.0.2.tgz

- Comprobar la versión de java e instalar la JDK correspondiente si es necesario:
  # java -version
  # rpm -iv /var/tmp/jdk-8u131-linux-x64.rpm

- Comprobar que la nueva versión de JAVA instalada no interfiere con resto de aplicativos (comprobar que el java por defecto sigue siendo el mismo):
  # java -version
  # update-alternatives --display java

- Ubicar el software de Kafka en /opt y desplegar:
  # mv /var/tmp/kafka_2.11-0.11.0.2.tgz /opt
  # cd /opt
  # tar xvfz kafka_2.11-0.11.0.2.tgz
  # rm /opt/kafka_2.11-0.11.0.2.tgz

- Crear enlace simbólico para ubicar los logs en la partición deseada:
  # mkdir /var/log/kafka
  # cd /opt/kafka_2.11-0.11.0.2
  # rm -fr logs/
  # ln -s /var/log/kafka logs
  # ls -rtl logs

- Crear enlace simbólico para acceder a la configuración vía /etc:
  # cd /etc
  # ln -s /opt/kafka_2.11-0.11.0.2/config kafka
  # ls -rtl kafka

- Añadir los comandos de Kafka a la variable PATH:
  # view $HOME/.bash_profile
  ...
  # Kafka PATH
  PATH=$PATH:/opt/kafka_2.11-0.11.0.2/bin
  export PATH

- Modificar el script de Kafka "kafka-run-class.sh" para forzarle a usar la versión 1.8 de Java:
  # view /opt/kafka_2.11-0.11.0.2/bin/kafka-run-class.sh
  ...
  # Force java to use
  JAVA_HOME=/usr/java/jdk1.8.0_131
  
  # Which java to use
  if [ -z "$JAVA_HOME" ]; then
    JAVA="java"
  else
    JAVA="$JAVA_HOME/bin/java"
  fi
  ...

-----------------------------------------------------------------------------------------------------------------------------

2. CONFIGURACIÓN

- Analizar el disco disponible y definir la estrategia de ubicación de los topics, asi como la retención de los datos:

  TIPO DISCO      PUNTO MONTAJE       DISCO DISPONIBLE PARA KAFKA
  --------------------------------------------------------------------------
  SAS 15K         /var/lib/data        400 GB x6 =  2400 GB
  SATA SSD        /var/lib/data_ssd   1840 GB x6 = 11040 GB <- Usaremos este
  --------------------------------------------------------------------------
                                    
  TOPIC               PUERTO  UBICACIÓN                           DISCO TOTAL     REPLICACION     DISCO EFECTIVO
  --------------------------------------------------------------------------------------------------------------
  raw_logs            9092    /var/lib/data_ssd/kafka             1000 GB         factor 2        2000 GB
  beautified_logs     9092    /var/lib/data_ssd/kafka             4400 GB         factor 2        8800 GB
  aggregated_metrics  9092    /var/lib/data_ssd/kafka              100 GB         factor 2         200 GB
  control_flow        9092    /var/lib/data_sdd/kafka              500 MB         factor 2           1 GB
  --------------------------------------------------------------------------------------------------------------

- Crear la ubicación de los datos de los topics:
  # mkdir /var/lib/data_ssd/kafka
 
- Configurar el Broker:
  # view /etc/kafka/server.properties
  ...
  broker.id=1
  log.dirs=/var/lib/data_ssd/kafka
  num.partitions=6
  offsets.topic.replication.factor=2
  transaction.state.log.replication.factor=2
  transaction.state.log.min.isr=2
  zookeeper.connect=node1:2181,node2:2181,node3:2181,node4:2181,node5:2181,node6:2181,node7:2181
  group.initial.rebalance.delay.ms=3
  ...
  (cada nodo tiene que tener un broker.id único por cada Broker)

- Arrancar los Broker de Kafka:
  # kafka-server-start.sh -daemon /etc/kafka/server.properties
  # jps

- Arrancar un Topic de prueba (ejecutar desde cualquier nodo del cluster de Kafka):
  # kafka-topics.sh --create --zookeeper worker1:2181,worker2:2181,worker3:2181,worker4:2181,worker5:2181,worker6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=1073741824000 --topic raw_logs
  # kafka-topics.sh --create --zookeeper worker1:2181,worker2:2181,worker3:2181,worker4:2181,worker5:2181,worker6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=4724464025600 --topic beautified_logs
  # kafka-topics.sh --create --zookeeper worker1:2181,worker2:2181,worker3:2181,worker4:2181,worker5:2181,worker6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=107374182400 --topic aggregated_metrics
  # kafka-topics.sh --create --zookeeper worker1:2181,worker2:2181,worker3:2181,worker4:2181,worker5:2181,worker6:2181 --partitions 6 --replication-factor 2 --config retention.bytes=524288000 --topic control_flow

- Comprobar la correcta creación de los Topics:
  # kafka-topics.sh --list --zookeeper worker1:2181,worker2:2181,worker3:2181,worker4:2181,worker5:2181,worker6:2181
  aggregated_metrics
  beautified_logs
  control_flow
  raw_logs

  # kafka-topics.sh --describe --zookeeper worker1:2181,worker2:2181,worker3:2181,worker4:2181,worker5:2181,worker6:2181
  Topic:aggregated_metrics        PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=107374182400
          Topic: aggregated_metrics       Partition: 0    Leader: 5       Replicas: 5,3   Isr: 5,3
          Topic: aggregated_metrics       Partition: 1    Leader: 6       Replicas: 6,4   Isr: 6,4
          Topic: aggregated_metrics       Partition: 2    Leader: 1       Replicas: 1,5   Isr: 1,5
          Topic: aggregated_metrics       Partition: 3    Leader: 2       Replicas: 2,6   Isr: 2,6
          Topic: aggregated_metrics       Partition: 4    Leader: 3       Replicas: 3,1   Isr: 3,1
          Topic: aggregated_metrics       Partition: 5    Leader: 4       Replicas: 4,2   Isr: 4,2
  Topic:beautified_logs   PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=4724464025600
          Topic: beautified_logs  Partition: 0    Leader: 4       Replicas: 4,6   Isr: 4,6
          Topic: beautified_logs  Partition: 1    Leader: 5       Replicas: 5,1   Isr: 5,1
          Topic: beautified_logs  Partition: 2    Leader: 6       Replicas: 6,2   Isr: 6,2
          Topic: beautified_logs  Partition: 3    Leader: 1       Replicas: 1,3   Isr: 1,3
          Topic: beautified_logs  Partition: 4    Leader: 2       Replicas: 2,4   Isr: 2,4
          Topic: beautified_logs  Partition: 5    Leader: 3       Replicas: 3,5   Isr: 3,5
  Topic:control_flow      PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=524288000
          Topic: control_flow     Partition: 0    Leader: 2       Replicas: 2,4   Isr: 2,4
          Topic: control_flow     Partition: 1    Leader: 3       Replicas: 3,5   Isr: 3,5
          Topic: control_flow     Partition: 2    Leader: 4       Replicas: 4,6   Isr: 4,6
          Topic: control_flow     Partition: 3    Leader: 5       Replicas: 5,1   Isr: 5,1
          Topic: control_flow     Partition: 4    Leader: 6       Replicas: 6,2   Isr: 6,2
          Topic: control_flow     Partition: 5    Leader: 1       Replicas: 1,3   Isr: 1,3
  Topic:raw_logs  PartitionCount:6        ReplicationFactor:2     Configs:retention.bytes=1073741824000
          Topic: raw_logs Partition: 0    Leader: 5       Replicas: 5,4   Isr: 5,4
          Topic: raw_logs Partition: 1    Leader: 6       Replicas: 6,5   Isr: 6,5
          Topic: raw_logs Partition: 2    Leader: 1       Replicas: 1,6   Isr: 1,6
          Topic: raw_logs Partition: 3    Leader: 2       Replicas: 2,1   Isr: 2,1
          Topic: raw_logs Partition: 4    Leader: 3       Replicas: 3,2   Isr: 3,2
          Topic: raw_logs Partition: 5    Leader: 4       Replicas: 4,3   Isr: 4,3

- Crear un Productor y volcar su salida al Topic de prueba:
  # kafka-console-producer.sh --broker-list worker1:9092,worker2:9092,worker3:9092,worker4:9092,worker5:9092,worker6:9092 --topic raw_logs

- Crear un Consumidor y leer el contenido del Topic de prueba:
  # kafka-console-consumer.sh --zookeeper worker1:2181,worker2:2181,worker3:2181,worker4:2181,worker5:2181,worker6:2181 --from-beginning --topic raw_logs

-----------------------------------------------------------------------------------------------------------------------------

3. COSAS PENDIENTES

- Configurar rotado y retención de los logs del propio Kafka
- Configurar el Broker de Kafka como un servicio.
- Hacer correr los procesos o servicio de Kafka con un usuario propio.
- Identificar las comunicaciones internas entre nodos y con otros sistemas (ZooKeeper, Flink y Logstash), habilitar el servicio firewalld y configurar las correspondientes reglas.


